{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[MH] Ode To Code - AutoML Libraries",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1r07UxnssiKs"
      },
      "outputs": [],
      "source": [
        "train_url = 'https://raw.githubusercontent.com/sidt-ai/data-science-competitions/main/machinehack/ode_to_code_2022/data/raw/train.csv'\n",
        "test_url = 'https://raw.githubusercontent.com/sidt-ai/data-science-competitions/main/machinehack/ode_to_code_2022/data/raw/test.csv'\n",
        "sub_url = 'https://raw.githubusercontent.com/sidt-ai/data-science-competitions/main/machinehack/ode_to_code_2022/data/raw/sample_submission.csv'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "P6_WAjY33Gnn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(train_url)\n",
        "\n",
        "test = pd.read_csv(test_url)\n",
        "test.drop(['season'], axis=1, inplace=True)\n",
        "\n",
        "sub = pd.read_csv(sub_url)"
      ],
      "metadata": {
        "id": "Icrkb_-kwERU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AutoGluon (Model 2)"
      ],
      "metadata": {
        "id": "4KhFlFsv3ZeE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m pip install --quiet pip\n",
        "!python3 -m pip install --quiet setuptools wheel\n",
        "!python3 -m pip install --quiet \"mxnet<2.0.0\"\n",
        "!python3 -m pip install --quiet autogluon"
      ],
      "metadata": {
        "id": "Dkz-GQ9Onk_4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d15bea6f-e002-4ea3-9349-ec936e4764dc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 47.3 MB 1.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 352 kB 8.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 56 kB 162 kB/s \n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 273 kB 68.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 22.3 MB 1.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 27.4 MB 1.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 210 kB 70.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 822 kB 55.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 131 kB 80.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 35.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 119 kB 71.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 60.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 53.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 296 kB 53.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 166.7 MB 17 kB/s \n",
            "\u001b[K     |████████████████████████████████| 189 kB 65.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 62.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 67.3 MB 13 kB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 68.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 54.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 64 kB 2.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 51.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 47.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 90 kB 5.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 377 kB 79.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 243 kB 76.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 54.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 133 kB 80.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 57.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.6 MB 44.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 61 kB 499 kB/s \n",
            "\u001b[K     |████████████████████████████████| 856 kB 52.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 79 kB 7.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 8.5 MB 72.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 79.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 104 kB 72.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 69 kB 7.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 42 kB 886 kB/s \n",
            "\u001b[K     |████████████████████████████████| 75 kB 4.4 MB/s \n",
            "\u001b[?25h  Building wheel for contextvars (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for openml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for liac-arff (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "markdown 3.3.6 requires importlib-metadata>=4.4; python_version < \"3.10\", but you have importlib-metadata 4.2.0 which is incompatible.\n",
            "gym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.0.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from autogluon.tabular import TabularPredictor"
      ],
      "metadata": {
        "id": "qvm2ChI74TUQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label = 'season'\n",
        "eval_metric = 'accuracy'\n",
        "save_path = '/AutoGluons/'\n",
        "\n",
        "predictor = TabularPredictor(label=label, eval_metric=eval_metric, \n",
        "                             path=save_path, verbosity=2)\n",
        "predictor.fit(train, presets='best_quality', time_limit=600)\n",
        "\n",
        "results = predictor.fit_summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slqJzRGY4Xo7",
        "outputId": "acdb35d0-c3c2-4be9-dafe-42727d8ad241"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Presets specified: ['best_quality']\n",
            "Beginning AutoGluon training ... Time limit = 600s\n",
            "AutoGluon will save models to \"/AutoGluons/\"\n",
            "AutoGluon Version:  0.3.1\n",
            "Train Data Rows:    42748\n",
            "Train Data Columns: 13\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
            "\t4 unique label values:  ['a', 's', 'u', 'w']\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "NumExpr defaulting to 2 threads.\n",
            "Train Data Class Count: 4\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    12712.07 MB\n",
            "\tTrain Data (Original)  Memory Usage: 25.59 MB (0.2% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])  :  3 | ['cap-diameter', 'stem-height', 'stem-width']\n",
            "\t\t('object', []) : 10 | ['edible-poisonous', 'cap-shape', 'cap-color', 'does-bruise-or-bleed', 'gill-attachment', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])  : 7 | ['cap-shape', 'cap-color', 'gill-attachment', 'gill-color', 'stem-color', ...]\n",
            "\t\t('float', [])     : 3 | ['cap-diameter', 'stem-height', 'stem-width']\n",
            "\t\t('int', ['bool']) : 3 | ['edible-poisonous', 'does-bruise-or-bleed', 'has-ring']\n",
            "\t0.4s = Fit runtime\n",
            "\t13 features in original data used to generate 13 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.46 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.57s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric argument of fit()\n",
            "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 399.52s of the 599.42s of remaining time.\n",
            "\t0.4876\t = Validation score   (accuracy)\n",
            "\t0.08s\t = Training   runtime\n",
            "\t0.21s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 399.08s of the 598.98s of remaining time.\n",
            "\t0.4774\t = Validation score   (accuracy)\n",
            "\t0.08s\t = Training   runtime\n",
            "\t0.22s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 398.64s of the 598.55s of remaining time.\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 18)\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 18)\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 18)\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 19)\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 20)\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 20)\n",
            "No improvement since epoch 2: early stopping\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 23)\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 26)\n",
            "\t0.5278\t = Validation score   (accuracy)\n",
            "\t376.85s\t = Training   runtime\n",
            "\t0.9s\t = Validation runtime\n",
            "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 20.28s of the 220.18s of remaining time.\n",
            "\tRan out of time, early stopping on iteration 48. Best iteration is:\n",
            "\t[15]\ttrain_set's multi_error: 0.483014\tvalid_set's multi_error: 0.484444\n",
            "\tTime limit exceeded... Skipping LightGBMXT_BAG_L1.\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 18.1s of the 218.0s of remaining time.\n",
            "\tRan out of time, early stopping on iteration 42. Best iteration is:\n",
            "\t[40]\ttrain_set's multi_error: 0.455696\tvalid_set's multi_error: 0.481637\n",
            "\tRan out of time, early stopping on iteration 44. Best iteration is:\n",
            "\t[42]\ttrain_set's multi_error: 0.452473\tvalid_set's multi_error: 0.484678\n",
            "\tRan out of time, early stopping on iteration 44. Best iteration is:\n",
            "\t[43]\ttrain_set's multi_error: 0.454085\tvalid_set's multi_error: 0.461754\n",
            "\tRan out of time, early stopping on iteration 45. Best iteration is:\n",
            "\t[12]\ttrain_set's multi_error: 0.485171\tvalid_set's multi_error: 0.482339\n",
            "\tRan out of time, early stopping on iteration 47. Best iteration is:\n",
            "\t[45]\ttrain_set's multi_error: 0.447535\tvalid_set's multi_error: 0.483743\n",
            "\tRan out of time, early stopping on iteration 49. Best iteration is:\n",
            "\t[42]\ttrain_set's multi_error: 0.453591\tvalid_set's multi_error: 0.476257\n",
            "\tRan out of time, early stopping on iteration 49. Best iteration is:\n",
            "\t[46]\ttrain_set's multi_error: 0.450316\tvalid_set's multi_error: 0.473216\n",
            "\tRan out of time, early stopping on iteration 52. Best iteration is:\n",
            "\t[47]\ttrain_set's multi_error: 0.445351\tvalid_set's multi_error: 0.472749\n",
            "\tRan out of time, early stopping on iteration 68. Best iteration is:\n",
            "\t[33]\ttrain_set's multi_error: 0.461662\tvalid_set's multi_error: 0.487131\n",
            "\t0.5217\t = Validation score   (accuracy)\n",
            "\t16.81s\t = Training   runtime\n",
            "\t0.71s\t = Validation runtime\n",
            "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 0.36s of the 200.27s of remaining time.\n",
            "\tWarning: Model is expected to require 23.2s to train, which exceeds the maximum time limit of 0.4s, skipping model...\n",
            "\tTime limit exceeded... Skipping RandomForestGini_BAG_L1.\n",
            "Completed 1/20 k-fold bagging repeats ...\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 199.85s of remaining time.\n",
            "\t0.5285\t = Validation score   (accuracy)\n",
            "\t3.71s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting 11 L2 models ...\n",
            "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 196.11s of the 196.09s of remaining time.\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 8)\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 8)\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 8)\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 7)\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 6)\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 6)\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 7)\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 8)\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 9)\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 11)\n",
            "\t0.5242\t = Validation score   (accuracy)\n",
            "\t185.93s\t = Training   runtime\n",
            "\t1.18s\t = Validation runtime\n",
            "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 8.62s of the 8.59s of remaining time.\n",
            "\tRan out of time, early stopping on iteration 5. Best iteration is:\n",
            "\t[5]\ttrain_set's multi_error: 0.491436\tvalid_set's multi_error: 0.492865\n",
            "\tRan out of time, early stopping on iteration 8. Best iteration is:\n",
            "\t[8]\ttrain_set's multi_error: 0.486003\tvalid_set's multi_error: 0.484444\n",
            "\tRan out of time, early stopping on iteration 8. Best iteration is:\n",
            "\t[8]\ttrain_set's multi_error: 0.486653\tvalid_set's multi_error: 0.48538\n",
            "\tRan out of time, early stopping on iteration 8. Best iteration is:\n",
            "\t[8]\ttrain_set's multi_error: 0.486237\tvalid_set's multi_error: 0.486082\n",
            "\tRan out of time, early stopping on iteration 9. Best iteration is:\n",
            "\t[9]\ttrain_set's multi_error: 0.485873\tvalid_set's multi_error: 0.486082\n",
            "\tRan out of time, early stopping on iteration 8. Best iteration is:\n",
            "\t[8]\ttrain_set's multi_error: 0.486549\tvalid_set's multi_error: 0.48538\n",
            "\tRan out of time, early stopping on iteration 9. Best iteration is:\n",
            "\t[9]\ttrain_set's multi_error: 0.485717\tvalid_set's multi_error: 0.487719\n",
            "\tRan out of time, early stopping on iteration 10. Best iteration is:\n",
            "\t[10]\ttrain_set's multi_error: 0.485041\tvalid_set's multi_error: 0.489825\n",
            "\tRan out of time, early stopping on iteration 11. Best iteration is:\n",
            "\t[10]\ttrain_set's multi_error: 0.485939\tvalid_set's multi_error: 0.482686\n",
            "\tRan out of time, early stopping on iteration 13. Best iteration is:\n",
            "\t[11]\ttrain_set's multi_error: 0.484665\tvalid_set's multi_error: 0.485728\n",
            "\t0.5134\t = Validation score   (accuracy)\n",
            "\t8.17s\t = Training   runtime\n",
            "\t0.26s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L2 ... Training model for up to 0.02s of the -0.01s of remaining time.\n",
            "\tRan out of time, early stopping on iteration 1. Best iteration is:\n",
            "\t[1]\ttrain_set's multi_error: 0.506355\tvalid_set's multi_error: 0.506199\n",
            "\tTime limit exceeded... Skipping LightGBM_BAG_L2.\n",
            "Completed 1/20 k-fold bagging repeats ...\n",
            "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -0.71s of remaining time.\n",
            "\t0.5243\t = Validation score   (accuracy)\n",
            "\t3.2s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 603.97s ...\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/AutoGluons/\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Summary of fit() ***\n",
            "Estimated performance of each model:\n",
            "                    model  score_val  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0     WeightedEnsemble_L2   0.528539       1.825294  397.458472                0.005249           3.711689            2       True          5\n",
            "1  NeuralNetFastAI_BAG_L1   0.527838       0.896321  376.853164                0.896321         376.853164            1       True          3\n",
            "2     WeightedEnsemble_L3   0.524258       3.476197  591.133706                0.006577           3.204824            3       True          8\n",
            "3  NeuralNetFastAI_BAG_L2   0.524212       3.212845  579.755080                1.177693         185.930678            2       True          6\n",
            "4         LightGBM_BAG_L1   0.521685       0.710322   16.812191                0.710322          16.812191            1       True          4\n",
            "5       LightGBMXT_BAG_L2   0.513381       2.291927  401.998204                0.256775           8.173801            2       True          7\n",
            "6   KNeighborsUnif_BAG_L1   0.487555       0.213402    0.081427                0.213402           0.081427            1       True          1\n",
            "7   KNeighborsDist_BAG_L1   0.477426       0.215106    0.077619                0.215106           0.077619            1       True          2\n",
            "Number of models trained: 8\n",
            "Types of models trained:\n",
            "{'StackerEnsembleModel_KNN', 'WeightedEnsembleModel', 'StackerEnsembleModel_LGB', 'StackerEnsembleModel_NNFastAiTabular'}\n",
            "Bagging used: True  (with 10 folds)\n",
            "Multi-layer stack-ensembling used: True  (with 3 levels)\n",
            "Feature Metadata (Processed):\n",
            "(raw dtype, special dtypes):\n",
            "('category', [])  : 7 | ['cap-shape', 'cap-color', 'gill-attachment', 'gill-color', 'stem-color', ...]\n",
            "('float', [])     : 3 | ['cap-diameter', 'stem-height', 'stem-width']\n",
            "('int', ['bool']) : 3 | ['edible-poisonous', 'does-bruise-or-bleed', 'has-ring']\n",
            "Plot summary of models saved to file: /AutoGluons/SummaryOfModels.html\n",
            "*** End of fit() summary ***\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = predictor.predict(test)"
      ],
      "metadata": {
        "id": "C_Khecl9m6H-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sub2 = sub.copy()\n",
        "sub2['season'] = preds\n",
        "sub2.to_csv('sub2.csv', index=False)"
      ],
      "metadata": {
        "id": "8eoJg93bnsdr"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# del predictor\n",
        "# gc.collect()"
      ],
      "metadata": {
        "id": "-NY4GOVBGq3U"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# H20 AutoML (Model 3)"
      ],
      "metadata": {
        "id": "LAOmAqpIgznY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet --upgrade h2o"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7dPvp0IHL5y",
        "outputId": "c9b30852-e709-48b5-9721-c2c543a82a20"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 175.8 MB 30 kB/s \n",
            "\u001b[?25h  Building wheel for h2o (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import h2o\n",
        "from h2o.automl import H2OAutoML"
      ],
      "metadata": {
        "id": "i_GTi-E59OuX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h2o.init()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "45Dg1iDiIRLW",
        "outputId": "0b3ee490-4ef8-4663-b86d-77a420673ed4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n",
            "Attempting to start a local H2O server...\n",
            "  Java Version: openjdk version \"11.0.13\" 2021-10-19; OpenJDK Runtime Environment (build 11.0.13+8-Ubuntu-0ubuntu1.18.04); OpenJDK 64-Bit Server VM (build 11.0.13+8-Ubuntu-0ubuntu1.18.04, mixed mode, sharing)\n",
            "  Starting server from /usr/local/lib/python3.7/dist-packages/h2o/backend/bin/h2o.jar\n",
            "  Ice root: /tmp/tmprddhu4uf\n",
            "  JVM stdout: /tmp/tmprddhu4uf/h2o_unknownUser_started_from_python.out\n",
            "  JVM stderr: /tmp/tmprddhu4uf/h2o_unknownUser_started_from_python.err\n",
            "  Server is running at http://127.0.0.1:54321\n",
            "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n",
              "<td>03 secs</td></tr>\n",
              "<tr><td>H2O_cluster_timezone:</td>\n",
              "<td>Etc/UTC</td></tr>\n",
              "<tr><td>H2O_data_parsing_timezone:</td>\n",
              "<td>UTC</td></tr>\n",
              "<tr><td>H2O_cluster_version:</td>\n",
              "<td>3.34.0.7</td></tr>\n",
              "<tr><td>H2O_cluster_version_age:</td>\n",
              "<td>27 days </td></tr>\n",
              "<tr><td>H2O_cluster_name:</td>\n",
              "<td>H2O_from_python_unknownUser_cef9ys</td></tr>\n",
              "<tr><td>H2O_cluster_total_nodes:</td>\n",
              "<td>1</td></tr>\n",
              "<tr><td>H2O_cluster_free_memory:</td>\n",
              "<td>3.172 Gb</td></tr>\n",
              "<tr><td>H2O_cluster_total_cores:</td>\n",
              "<td>2</td></tr>\n",
              "<tr><td>H2O_cluster_allowed_cores:</td>\n",
              "<td>2</td></tr>\n",
              "<tr><td>H2O_cluster_status:</td>\n",
              "<td>locked, healthy</td></tr>\n",
              "<tr><td>H2O_connection_url:</td>\n",
              "<td>http://127.0.0.1:54321</td></tr>\n",
              "<tr><td>H2O_connection_proxy:</td>\n",
              "<td>{\"http\": null, \"https\": null}</td></tr>\n",
              "<tr><td>H2O_internal_security:</td>\n",
              "<td>False</td></tr>\n",
              "<tr><td>H2O_API_Extensions:</td>\n",
              "<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
              "<tr><td>Python_version:</td>\n",
              "<td>3.7.12 final</td></tr></table></div>"
            ],
            "text/plain": [
              "--------------------------  ------------------------------------------------------------------\n",
              "H2O_cluster_uptime:         03 secs\n",
              "H2O_cluster_timezone:       Etc/UTC\n",
              "H2O_data_parsing_timezone:  UTC\n",
              "H2O_cluster_version:        3.34.0.7\n",
              "H2O_cluster_version_age:    27 days\n",
              "H2O_cluster_name:           H2O_from_python_unknownUser_cef9ys\n",
              "H2O_cluster_total_nodes:    1\n",
              "H2O_cluster_free_memory:    3.172 Gb\n",
              "H2O_cluster_total_cores:    2\n",
              "H2O_cluster_allowed_cores:  2\n",
              "H2O_cluster_status:         locked, healthy\n",
              "H2O_connection_url:         http://127.0.0.1:54321\n",
              "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
              "H2O_internal_security:      False\n",
              "H2O_API_Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4\n",
              "Python_version:             3.7.12 final\n",
              "--------------------------  ------------------------------------------------------------------"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h2o_train = h2o.H2OFrame(train)\n",
        "h2o_test = h2o.H2OFrame(test)\n",
        "\n",
        "h2o_train['season'] = h2o.H2OFrame(train['season'].to_numpy().ravel()).asfactor()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9L8xo45JQM-",
        "outputId": "ef4c06f5-c03c-4d30-8eb5-fce4ad42ee62"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
            "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
            "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features = [f for f in test.columns]"
      ],
      "metadata": {
        "id": "e1600Q86Kpp8"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = H2OAutoML(stopping_metric='misclassification', max_runtime_secs=600)\n",
        "model3.train(x=features, y='season', training_frame=h2o_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Z45-gAeJULB",
        "outputId": "60d9f4ff-608e-4fe5-87f6-596af933bb9f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AutoML progress: |███████████████████████████████████████████████████████████████| (done) 100%\n",
            "Model Details\n",
            "=============\n",
            "H2OStackedEnsembleEstimator :  Stacked Ensemble\n",
            "Model Key:  StackedEnsemble_BestOfFamily_1_AutoML_1_20220118_81554\n",
            "\n",
            "No model summary for this model\n",
            "\n",
            "ModelMetricsMultinomialGLM: stackedensemble\n",
            "** Reported on train data. **\n",
            "\n",
            "MSE: 0.2498041524871099\n",
            "RMSE: 0.4998041141158303\n",
            "\n",
            "ModelMetricsMultinomialGLM: stackedensemble\n",
            "** Reported on cross-validation data. **\n",
            "\n",
            "MSE: 0.2802817622030454\n",
            "RMSE: 0.5294164355241018\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3.leaderboard"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "BBurpcmvLen2",
        "outputId": "754d839f-7d81-4199-c193-c71b06fd006d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table>\n",
              "<thead>\n",
              "<tr><th>model_id                                              </th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">     mse</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>StackedEnsemble_BestOfFamily_1_AutoML_1_20220118_81554</td><td style=\"text-align: right;\">              0.515821</td><td style=\"text-align: right;\"> 0.75375 </td><td style=\"text-align: right;\">0.529416</td><td style=\"text-align: right;\">0.280282</td></tr>\n",
              "<tr><td>XGBoost_1_AutoML_1_20220118_81554                     </td><td style=\"text-align: right;\">              0.547336</td><td style=\"text-align: right;\"> 0.788386</td><td style=\"text-align: right;\">0.541153</td><td style=\"text-align: right;\">0.292846</td></tr>\n",
              "<tr><td>GBM_1_AutoML_1_20220118_81554                         </td><td style=\"text-align: right;\">              0.584124</td><td style=\"text-align: right;\"> 0.790964</td><td style=\"text-align: right;\">0.546989</td><td style=\"text-align: right;\">0.299197</td></tr>\n",
              "<tr><td>GLM_1_AutoML_1_20220118_81554                         </td><td style=\"text-align: right;\">              0.634337</td><td style=\"text-align: right;\"> 0.921559</td><td style=\"text-align: right;\">0.580257</td><td style=\"text-align: right;\">0.336698</td></tr>\n",
              "</tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds3 = model3.leader.predict(h2o_test).as_data_frame()['predict']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQ_K8dyULobB",
        "outputId": "4357a957-eaf1-4e3e-da68-32573dc2942b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stackedensemble prediction progress: |███████████████████████████████████████████| (done) 100%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sub3 = sub.copy()\n",
        "sub3['season'] = preds3\n",
        "sub3.to_csv('sub3.csv', index=False)"
      ],
      "metadata": {
        "id": "rcbXE5HQL7bp"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# del model3\n",
        "# gc.collect()"
      ],
      "metadata": {
        "id": "Ds4bu8zxMIeP"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLJAR (Model 4)"
      ],
      "metadata": {
        "id": "M67BPeCMg2T-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install --quiet --uprade mljar-supervised"
      ],
      "metadata": {
        "id": "kg1YAHvFMUeo"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from supervised.automl import AutoML\n",
        "# from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "0__A7Um2NPA8"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model4 = AutoML(mode='compete', \n",
        "#                 ml_task='multiclass_classification', \n",
        "#                 eval_metric='accuracy', \n",
        "#                 total_time_limit=600)\n",
        "\n",
        "# model4.fit(X=train[features], y=train['season'])"
      ],
      "metadata": {
        "id": "-NUJnzeONWNo"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preds4 = model4.predict(test)"
      ],
      "metadata": {
        "id": "V9Bpl5oEOLWf"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sub4 = sub.copy()\n",
        "# sub4['season'] = preds4\n",
        "# sub4.to_csv('sub4.csv', index=False)"
      ],
      "metadata": {
        "id": "BPV5Wx4BOV4C"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# del model4\n",
        "# gc.collect()"
      ],
      "metadata": {
        "id": "LTT7C0CCObQo"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FLAML (Model 5)"
      ],
      "metadata": {
        "id": "C18p_fdQhAB8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet --upgrade flaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FyAOxOPMt0b",
        "outputId": "8c0824d6-9891-4b1a-9cf7-4457f8780059"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 142 kB 5.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157.5 MB 51 kB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flaml import AutoML"
      ],
      "metadata": {
        "id": "B-_8AYHJMycc"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model5 = AutoML()\n",
        "model5.fit(train[test.columns], train['season'], \n",
        "           task='classification', time_budget=600)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TG9jO4MoM407",
        "outputId": "45640d69-1f08-46cc-9cda-e4374abfb5b6"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[flaml.automl: 01-18 08:51:52] {2007} INFO - task = classification\n",
            "task = classification\n",
            "[flaml.automl: 01-18 08:51:52] {2009} INFO - Data split method: stratified\n",
            "Data split method: stratified\n",
            "[flaml.automl: 01-18 08:51:52] {2013} INFO - Evaluation method: cv\n",
            "Evaluation method: cv\n",
            "[flaml.automl: 01-18 08:51:52] {2113} INFO - Minimizing error metric: log_loss\n",
            "Minimizing error metric: log_loss\n",
            "[flaml.automl: 01-18 08:51:52] {2170} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'lrl1']\n",
            "List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'lrl1']\n",
            "[flaml.automl: 01-18 08:51:52] {2437} INFO - iteration 0, current learner lgbm\n",
            "iteration 0, current learner lgbm\n",
            "[flaml.automl: 01-18 08:51:53] {2551} INFO - Estimated sufficient time budget=9075s. Estimated necessary time budget=223s.\n",
            "Estimated sufficient time budget=9075s. Estimated necessary time budget=223s.\n",
            "[flaml.automl: 01-18 08:51:53] {2603} INFO -  at 1.2s,\testimator lgbm's best error=1.0245,\tbest estimator lgbm's best error=1.0245\n",
            " at 1.2s,\testimator lgbm's best error=1.0245,\tbest estimator lgbm's best error=1.0245\n",
            "[flaml.automl: 01-18 08:51:53] {2437} INFO - iteration 1, current learner lgbm\n",
            "iteration 1, current learner lgbm\n",
            "[flaml.automl: 01-18 08:51:54] {2603} INFO -  at 2.0s,\testimator lgbm's best error=1.0245,\tbest estimator lgbm's best error=1.0245\n",
            " at 2.0s,\testimator lgbm's best error=1.0245,\tbest estimator lgbm's best error=1.0245\n",
            "[flaml.automl: 01-18 08:51:54] {2437} INFO - iteration 2, current learner lgbm\n",
            "iteration 2, current learner lgbm\n",
            "[flaml.automl: 01-18 08:51:55] {2603} INFO -  at 2.9s,\testimator lgbm's best error=0.9861,\tbest estimator lgbm's best error=0.9861\n",
            " at 2.9s,\testimator lgbm's best error=0.9861,\tbest estimator lgbm's best error=0.9861\n",
            "[flaml.automl: 01-18 08:51:55] {2437} INFO - iteration 3, current learner xgboost\n",
            "iteration 3, current learner xgboost\n",
            "[flaml.automl: 01-18 08:51:56] {2603} INFO -  at 3.8s,\testimator xgboost's best error=1.2504,\tbest estimator lgbm's best error=0.9861\n",
            " at 3.8s,\testimator xgboost's best error=1.2504,\tbest estimator lgbm's best error=0.9861\n",
            "[flaml.automl: 01-18 08:51:56] {2437} INFO - iteration 4, current learner lgbm\n",
            "iteration 4, current learner lgbm\n",
            "[flaml.automl: 01-18 08:51:57] {2603} INFO -  at 5.1s,\testimator lgbm's best error=0.8718,\tbest estimator lgbm's best error=0.8718\n",
            " at 5.1s,\testimator lgbm's best error=0.8718,\tbest estimator lgbm's best error=0.8718\n",
            "[flaml.automl: 01-18 08:51:57] {2437} INFO - iteration 5, current learner lgbm\n",
            "iteration 5, current learner lgbm\n",
            "[flaml.automl: 01-18 08:51:58] {2603} INFO -  at 5.9s,\testimator lgbm's best error=0.8718,\tbest estimator lgbm's best error=0.8718\n",
            " at 5.9s,\testimator lgbm's best error=0.8718,\tbest estimator lgbm's best error=0.8718\n",
            "[flaml.automl: 01-18 08:51:58] {2437} INFO - iteration 6, current learner lgbm\n",
            "iteration 6, current learner lgbm\n",
            "[flaml.automl: 01-18 08:51:59] {2603} INFO -  at 7.3s,\testimator lgbm's best error=0.8718,\tbest estimator lgbm's best error=0.8718\n",
            " at 7.3s,\testimator lgbm's best error=0.8718,\tbest estimator lgbm's best error=0.8718\n",
            "[flaml.automl: 01-18 08:51:59] {2437} INFO - iteration 7, current learner lgbm\n",
            "iteration 7, current learner lgbm\n",
            "[flaml.automl: 01-18 08:52:00] {2603} INFO -  at 8.5s,\testimator lgbm's best error=0.8718,\tbest estimator lgbm's best error=0.8718\n",
            " at 8.5s,\testimator lgbm's best error=0.8718,\tbest estimator lgbm's best error=0.8718\n",
            "[flaml.automl: 01-18 08:52:00] {2437} INFO - iteration 8, current learner lgbm\n",
            "iteration 8, current learner lgbm\n",
            "[flaml.automl: 01-18 08:52:01] {2603} INFO -  at 9.4s,\testimator lgbm's best error=0.8718,\tbest estimator lgbm's best error=0.8718\n",
            " at 9.4s,\testimator lgbm's best error=0.8718,\tbest estimator lgbm's best error=0.8718\n",
            "[flaml.automl: 01-18 08:52:01] {2437} INFO - iteration 9, current learner xgboost\n",
            "iteration 9, current learner xgboost\n",
            "[flaml.automl: 01-18 08:52:02] {2603} INFO -  at 10.3s,\testimator xgboost's best error=1.2504,\tbest estimator lgbm's best error=0.8718\n",
            " at 10.3s,\testimator xgboost's best error=1.2504,\tbest estimator lgbm's best error=0.8718\n",
            "[flaml.automl: 01-18 08:52:02] {2437} INFO - iteration 10, current learner xgboost\n",
            "iteration 10, current learner xgboost\n",
            "[flaml.automl: 01-18 08:52:03] {2603} INFO -  at 11.1s,\testimator xgboost's best error=1.1257,\tbest estimator lgbm's best error=0.8718\n",
            " at 11.1s,\testimator xgboost's best error=1.1257,\tbest estimator lgbm's best error=0.8718\n",
            "[flaml.automl: 01-18 08:52:03] {2437} INFO - iteration 11, current learner extra_tree\n",
            "iteration 11, current learner extra_tree\n",
            "[flaml.automl: 01-18 08:52:05] {2603} INFO -  at 12.6s,\testimator extra_tree's best error=1.0389,\tbest estimator lgbm's best error=0.8718\n",
            " at 12.6s,\testimator extra_tree's best error=1.0389,\tbest estimator lgbm's best error=0.8718\n",
            "[flaml.automl: 01-18 08:52:05] {2437} INFO - iteration 12, current learner extra_tree\n",
            "iteration 12, current learner extra_tree\n",
            "[flaml.automl: 01-18 08:52:06] {2603} INFO -  at 14.2s,\testimator extra_tree's best error=1.0044,\tbest estimator lgbm's best error=0.8718\n",
            " at 14.2s,\testimator extra_tree's best error=1.0044,\tbest estimator lgbm's best error=0.8718\n",
            "[flaml.automl: 01-18 08:52:06] {2437} INFO - iteration 13, current learner rf\n",
            "iteration 13, current learner rf\n",
            "[flaml.automl: 01-18 08:52:08] {2603} INFO -  at 15.7s,\testimator rf's best error=1.0292,\tbest estimator lgbm's best error=0.8718\n",
            " at 15.7s,\testimator rf's best error=1.0292,\tbest estimator lgbm's best error=0.8718\n",
            "[flaml.automl: 01-18 08:52:08] {2437} INFO - iteration 14, current learner rf\n",
            "iteration 14, current learner rf\n",
            "[flaml.automl: 01-18 08:52:09] {2603} INFO -  at 17.1s,\testimator rf's best error=0.9802,\tbest estimator lgbm's best error=0.8718\n",
            " at 17.1s,\testimator rf's best error=0.9802,\tbest estimator lgbm's best error=0.8718\n",
            "[flaml.automl: 01-18 08:52:09] {2437} INFO - iteration 15, current learner xgboost\n",
            "iteration 15, current learner xgboost\n",
            "[flaml.automl: 01-18 08:52:10] {2603} INFO -  at 18.0s,\testimator xgboost's best error=0.9792,\tbest estimator lgbm's best error=0.8718\n",
            " at 18.0s,\testimator xgboost's best error=0.9792,\tbest estimator lgbm's best error=0.8718\n",
            "[flaml.automl: 01-18 08:52:10] {2437} INFO - iteration 16, current learner rf\n",
            "iteration 16, current learner rf\n",
            "[flaml.automl: 01-18 08:52:12] {2603} INFO -  at 19.7s,\testimator rf's best error=0.9802,\tbest estimator lgbm's best error=0.8718\n",
            " at 19.7s,\testimator rf's best error=0.9802,\tbest estimator lgbm's best error=0.8718\n",
            "[flaml.automl: 01-18 08:52:12] {2437} INFO - iteration 17, current learner xgboost\n",
            "iteration 17, current learner xgboost\n",
            "[flaml.automl: 01-18 08:52:13] {2603} INFO -  at 20.6s,\testimator xgboost's best error=0.9792,\tbest estimator lgbm's best error=0.8718\n",
            " at 20.6s,\testimator xgboost's best error=0.9792,\tbest estimator lgbm's best error=0.8718\n",
            "[flaml.automl: 01-18 08:52:13] {2437} INFO - iteration 18, current learner lgbm\n",
            "iteration 18, current learner lgbm\n",
            "[flaml.automl: 01-18 08:52:16] {2603} INFO -  at 23.6s,\testimator lgbm's best error=0.8221,\tbest estimator lgbm's best error=0.8221\n",
            " at 23.6s,\testimator lgbm's best error=0.8221,\tbest estimator lgbm's best error=0.8221\n",
            "[flaml.automl: 01-18 08:52:16] {2437} INFO - iteration 19, current learner xgboost\n",
            "iteration 19, current learner xgboost\n",
            "[flaml.automl: 01-18 08:52:16] {2603} INFO -  at 24.4s,\testimator xgboost's best error=0.9792,\tbest estimator lgbm's best error=0.8221\n",
            " at 24.4s,\testimator xgboost's best error=0.9792,\tbest estimator lgbm's best error=0.8221\n",
            "[flaml.automl: 01-18 08:52:16] {2437} INFO - iteration 20, current learner rf\n",
            "iteration 20, current learner rf\n",
            "[flaml.automl: 01-18 08:52:18] {2603} INFO -  at 26.1s,\testimator rf's best error=0.9802,\tbest estimator lgbm's best error=0.8221\n",
            " at 26.1s,\testimator rf's best error=0.9802,\tbest estimator lgbm's best error=0.8221\n",
            "[flaml.automl: 01-18 08:52:18] {2437} INFO - iteration 21, current learner xgboost\n",
            "iteration 21, current learner xgboost\n",
            "[flaml.automl: 01-18 08:52:20] {2603} INFO -  at 27.6s,\testimator xgboost's best error=0.9045,\tbest estimator lgbm's best error=0.8221\n",
            " at 27.6s,\testimator xgboost's best error=0.9045,\tbest estimator lgbm's best error=0.8221\n",
            "[flaml.automl: 01-18 08:52:20] {2437} INFO - iteration 22, current learner lgbm\n",
            "iteration 22, current learner lgbm\n",
            "[flaml.automl: 01-18 08:52:21] {2603} INFO -  at 28.8s,\testimator lgbm's best error=0.8221,\tbest estimator lgbm's best error=0.8221\n",
            " at 28.8s,\testimator lgbm's best error=0.8221,\tbest estimator lgbm's best error=0.8221\n",
            "[flaml.automl: 01-18 08:52:21] {2437} INFO - iteration 23, current learner lgbm\n",
            "iteration 23, current learner lgbm\n",
            "[flaml.automl: 01-18 08:52:35] {2603} INFO -  at 42.7s,\testimator lgbm's best error=0.7618,\tbest estimator lgbm's best error=0.7618\n",
            " at 42.7s,\testimator lgbm's best error=0.7618,\tbest estimator lgbm's best error=0.7618\n",
            "[flaml.automl: 01-18 08:52:35] {2437} INFO - iteration 24, current learner extra_tree\n",
            "iteration 24, current learner extra_tree\n",
            "[flaml.automl: 01-18 08:52:36] {2603} INFO -  at 44.3s,\testimator extra_tree's best error=1.0044,\tbest estimator lgbm's best error=0.7618\n",
            " at 44.3s,\testimator extra_tree's best error=1.0044,\tbest estimator lgbm's best error=0.7618\n",
            "[flaml.automl: 01-18 08:52:36] {2437} INFO - iteration 25, current learner extra_tree\n",
            "iteration 25, current learner extra_tree\n",
            "[flaml.automl: 01-18 08:52:38] {2603} INFO -  at 45.9s,\testimator extra_tree's best error=1.0044,\tbest estimator lgbm's best error=0.7618\n",
            " at 45.9s,\testimator extra_tree's best error=1.0044,\tbest estimator lgbm's best error=0.7618\n",
            "[flaml.automl: 01-18 08:52:38] {2437} INFO - iteration 26, current learner lgbm\n",
            "iteration 26, current learner lgbm\n",
            "[flaml.automl: 01-18 08:52:57] {2603} INFO -  at 64.6s,\testimator lgbm's best error=0.7618,\tbest estimator lgbm's best error=0.7618\n",
            " at 64.6s,\testimator lgbm's best error=0.7618,\tbest estimator lgbm's best error=0.7618\n",
            "[flaml.automl: 01-18 08:52:57] {2437} INFO - iteration 27, current learner xgboost\n",
            "iteration 27, current learner xgboost\n",
            "[flaml.automl: 01-18 08:52:59] {2603} INFO -  at 67.0s,\testimator xgboost's best error=0.8628,\tbest estimator lgbm's best error=0.7618\n",
            " at 67.0s,\testimator xgboost's best error=0.8628,\tbest estimator lgbm's best error=0.7618\n",
            "[flaml.automl: 01-18 08:52:59] {2437} INFO - iteration 28, current learner xgboost\n",
            "iteration 28, current learner xgboost\n",
            "[flaml.automl: 01-18 08:53:01] {2603} INFO -  at 68.6s,\testimator xgboost's best error=0.8628,\tbest estimator lgbm's best error=0.7618\n",
            " at 68.6s,\testimator xgboost's best error=0.8628,\tbest estimator lgbm's best error=0.7618\n",
            "[flaml.automl: 01-18 08:53:01] {2437} INFO - iteration 29, current learner catboost\n",
            "iteration 29, current learner catboost\n",
            "[flaml.automl: 01-18 09:00:18] {2603} INFO -  at 506.4s,\testimator catboost's best error=0.7667,\tbest estimator lgbm's best error=0.7618\n",
            " at 506.4s,\testimator catboost's best error=0.7667,\tbest estimator lgbm's best error=0.7618\n",
            "[flaml.automl: 01-18 09:00:18] {2437} INFO - iteration 30, current learner xgboost\n",
            "iteration 30, current learner xgboost\n",
            "[flaml.automl: 01-18 09:00:21] {2603} INFO -  at 509.0s,\testimator xgboost's best error=0.7802,\tbest estimator lgbm's best error=0.7618\n",
            " at 509.0s,\testimator xgboost's best error=0.7802,\tbest estimator lgbm's best error=0.7618\n",
            "[flaml.automl: 01-18 09:00:21] {2437} INFO - iteration 31, current learner lgbm\n",
            "iteration 31, current learner lgbm\n",
            "[flaml.automl: 01-18 09:00:33] {2603} INFO -  at 521.5s,\testimator lgbm's best error=0.7618,\tbest estimator lgbm's best error=0.7618\n",
            " at 521.5s,\testimator lgbm's best error=0.7618,\tbest estimator lgbm's best error=0.7618\n",
            "[flaml.automl: 01-18 09:00:33] {2437} INFO - iteration 32, current learner lgbm\n",
            "iteration 32, current learner lgbm\n",
            "[flaml.automl: 01-18 09:00:48] {2603} INFO -  at 536.1s,\testimator lgbm's best error=0.7618,\tbest estimator lgbm's best error=0.7618\n",
            " at 536.1s,\testimator lgbm's best error=0.7618,\tbest estimator lgbm's best error=0.7618\n",
            "[flaml.automl: 01-18 09:00:48] {2437} INFO - iteration 33, current learner xgboost\n",
            "iteration 33, current learner xgboost\n",
            "[flaml.automl: 01-18 09:00:50] {2603} INFO -  at 538.5s,\testimator xgboost's best error=0.7802,\tbest estimator lgbm's best error=0.7618\n",
            " at 538.5s,\testimator xgboost's best error=0.7802,\tbest estimator lgbm's best error=0.7618\n",
            "[flaml.automl: 01-18 09:00:50] {2437} INFO - iteration 34, current learner xgboost\n",
            "iteration 34, current learner xgboost\n",
            "[flaml.automl: 01-18 09:00:52] {2603} INFO -  at 540.1s,\testimator xgboost's best error=0.7802,\tbest estimator lgbm's best error=0.7618\n",
            " at 540.1s,\testimator xgboost's best error=0.7802,\tbest estimator lgbm's best error=0.7618\n",
            "[flaml.automl: 01-18 09:00:52] {2437} INFO - iteration 35, current learner rf\n",
            "iteration 35, current learner rf\n",
            "[flaml.automl: 01-18 09:00:54] {2603} INFO -  at 541.6s,\testimator rf's best error=0.9641,\tbest estimator lgbm's best error=0.7618\n",
            " at 541.6s,\testimator rf's best error=0.9641,\tbest estimator lgbm's best error=0.7618\n",
            "[flaml.automl: 01-18 09:00:54] {2437} INFO - iteration 36, current learner xgboost\n",
            "iteration 36, current learner xgboost\n",
            "[flaml.automl: 01-18 09:00:59] {2603} INFO -  at 547.0s,\testimator xgboost's best error=0.7702,\tbest estimator lgbm's best error=0.7618\n",
            " at 547.0s,\testimator xgboost's best error=0.7702,\tbest estimator lgbm's best error=0.7618\n",
            "[flaml.automl: 01-18 09:00:59] {2437} INFO - iteration 37, current learner extra_tree\n",
            "iteration 37, current learner extra_tree\n",
            "[flaml.automl: 01-18 09:01:00] {2603} INFO -  at 548.5s,\testimator extra_tree's best error=0.9928,\tbest estimator lgbm's best error=0.7618\n",
            " at 548.5s,\testimator extra_tree's best error=0.9928,\tbest estimator lgbm's best error=0.7618\n",
            "[flaml.automl: 01-18 09:01:00] {2437} INFO - iteration 38, current learner xgboost\n",
            "iteration 38, current learner xgboost\n",
            "[flaml.automl: 01-18 09:01:03] {2603} INFO -  at 551.1s,\testimator xgboost's best error=0.7702,\tbest estimator lgbm's best error=0.7618\n",
            " at 551.1s,\testimator xgboost's best error=0.7702,\tbest estimator lgbm's best error=0.7618\n",
            "[flaml.automl: 01-18 09:01:03] {2437} INFO - iteration 39, current learner xgboost\n",
            "iteration 39, current learner xgboost\n",
            "[flaml.automl: 01-18 09:01:16] {2603} INFO -  at 563.7s,\testimator xgboost's best error=0.7702,\tbest estimator lgbm's best error=0.7618\n",
            " at 563.7s,\testimator xgboost's best error=0.7702,\tbest estimator lgbm's best error=0.7618\n",
            "[flaml.automl: 01-18 09:01:16] {2437} INFO - iteration 40, current learner lgbm\n",
            "iteration 40, current learner lgbm\n",
            "[flaml.automl: 01-18 09:01:31] {2603} INFO -  at 578.8s,\testimator lgbm's best error=0.7618,\tbest estimator lgbm's best error=0.7618\n",
            " at 578.8s,\testimator lgbm's best error=0.7618,\tbest estimator lgbm's best error=0.7618\n",
            "[flaml.automl: 01-18 09:01:31] {2437} INFO - iteration 41, current learner xgboost\n",
            "iteration 41, current learner xgboost\n",
            "[flaml.automl: 01-18 09:01:34] {2603} INFO -  at 581.9s,\testimator xgboost's best error=0.7702,\tbest estimator lgbm's best error=0.7618\n",
            " at 581.9s,\testimator xgboost's best error=0.7702,\tbest estimator lgbm's best error=0.7618\n",
            "[flaml.automl: 01-18 09:01:34] {2437} INFO - iteration 42, current learner xgboost\n",
            "iteration 42, current learner xgboost\n",
            "[flaml.automl: 01-18 09:01:43] {2603} INFO -  at 591.4s,\testimator xgboost's best error=0.7702,\tbest estimator lgbm's best error=0.7618\n",
            " at 591.4s,\testimator xgboost's best error=0.7702,\tbest estimator lgbm's best error=0.7618\n",
            "[flaml.automl: 01-18 09:01:43] {2437} INFO - iteration 43, current learner xgb_limitdepth\n",
            "iteration 43, current learner xgb_limitdepth\n",
            "[flaml.automl: 01-18 09:01:49] {2603} INFO -  at 597.2s,\testimator xgb_limitdepth's best error=0.8787,\tbest estimator lgbm's best error=0.7618\n",
            " at 597.2s,\testimator xgb_limitdepth's best error=0.8787,\tbest estimator lgbm's best error=0.7618\n",
            "[flaml.automl: 01-18 09:01:49] {2437} INFO - iteration 44, current learner rf\n",
            "iteration 44, current learner rf\n",
            "[flaml.automl: 01-18 09:01:51] {2603} INFO -  at 599.3s,\testimator rf's best error=0.9641,\tbest estimator lgbm's best error=0.7618\n",
            " at 599.3s,\testimator rf's best error=0.9641,\tbest estimator lgbm's best error=0.7618\n",
            "[flaml.automl: 01-18 09:01:51] {2437} INFO - iteration 45, current learner lrl1\n",
            "iteration 45, current learner lrl1\n",
            "No low-cost partial config given to the search algorithm. For cost-frugal search, consider providing low-cost values for cost-related hps via 'low_cost_partial_config'. More info can be found at https://microsoft.github.io/FLAML/docs/FAQ#about-low_cost_partial_config-in-tune\n",
            "[flaml.automl: 01-18 09:01:55] {2603} INFO -  at 602.6s,\testimator lrl1's best error=1.0177,\tbest estimator lgbm's best error=0.7618\n",
            " at 602.6s,\testimator lrl1's best error=1.0177,\tbest estimator lgbm's best error=0.7618\n",
            "[flaml.automl: 01-18 09:01:57] {2817} INFO - retrain lgbm for 2.9s\n",
            "retrain lgbm for 2.9s\n",
            "[flaml.automl: 01-18 09:01:57] {2822} INFO - retrained model: LGBMClassifier(colsample_bytree=0.763007791741338,\n",
            "               learning_rate=0.16645809713264254, max_bin=1023,\n",
            "               min_child_samples=6, n_estimators=164, num_leaves=20,\n",
            "               reg_alpha=0.0009765625, reg_lambda=0.10626868868028042,\n",
            "               verbose=-1)\n",
            "retrained model: LGBMClassifier(colsample_bytree=0.763007791741338,\n",
            "               learning_rate=0.16645809713264254, max_bin=1023,\n",
            "               min_child_samples=6, n_estimators=164, num_leaves=20,\n",
            "               reg_alpha=0.0009765625, reg_lambda=0.10626868868028042,\n",
            "               verbose=-1)\n",
            "[flaml.automl: 01-18 09:01:57] {2199} INFO - fit succeeded\n",
            "fit succeeded\n",
            "[flaml.automl: 01-18 09:01:57] {2201} INFO - Time taken to find the best model: 42.69464325904846\n",
            "Time taken to find the best model: 42.69464325904846\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds5 = model5.predict(test)"
      ],
      "metadata": {
        "id": "hjEroEO8NaBu"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sub5 = sub.copy()\n",
        "sub5['season'] = preds5\n",
        "sub5.to_csv('sub5.csv', index=False)"
      ],
      "metadata": {
        "id": "gVcE5fPMNdDq"
      },
      "execution_count": 55,
      "outputs": []
    }
  ]
}